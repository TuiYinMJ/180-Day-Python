# 进程与线程

## 1、基础概念

### 1、进程

​	比如我们打开一个QQ、微信、浏览器等，都是进程，多进程也就是多个进程，每个进程之间相互独立，互不影响，在系统上同时可以打开N个进程，比如一边听歌一边聊天一边刷网页

​	再专业点就是多进程可以同时启动多个进程，每个进程可以运行在不同的CPU核心上，所以进程需要cpu和内存



### 2、线程

​	启动多个进程会占用过多的内存资源，此时线程或许就可以解决这个问题

​	线程是进程的执行单元，线程之间共享进程的内存和资源，之间可以访问同一块内存，所以进程也就是线程的容器，每个进程至少包含一个线程，线程在进程内部运行

​	进程的创建和销毁需要较多的系统和处理器资源，而线程的创建和销毁相对较轻，因此多线程编程比多进程编程更加高效。



![image-20230629121430001](https://raw.githubusercontent.com/TuiYinMJ/Python-img/master/Python-img/202306291214129.png)

​	进程可以比喻为一家工厂，工厂有自己的地址空间和资源，就像进程有自己的地址空间和资源一样。

​	工厂的生产线可以比喻为线程，生产线上的工人可以比喻为线程中的执行代码。

​	每个工人都在生产线上独立地工作，他们共享工厂的资源，但是彼此之间相互独立，所以进程必须有线程，否则就是一个没有实际功能的死进程，且占用了资源

​	所以多线程也就是一个程序中有多个线程同时运行，每个线程可以处理不同的任务



### 3、其他概念

- **串行**：按顺序执行，前一个任务完成才执行下一个，好像做早餐，先泡咖啡、再烤面包、再刷锅洗碗，要按一定顺序，无法同时进行，这就是串行
- **并行**：同时执行多个任务，任务之间相互独立，没有先后，就像一个人在走路的时候仍然可以玩手机、唱歌、等等，前提是计算机拥有多核

![image-20230629122025043](https://raw.githubusercontent.com/TuiYinMJ/Python-img/master/Python-img/202306291220075.png)

​	就如上，12核

- **并发**：同一时间段发生多个任务，但不表示必须同时发生，只是同一时间段，比如，做饭等待的时候我去看电视，电视放广告了，我回去翻炒菜，这两个事情只是同一时间段发生，并不是同时进行
- **同步**：sync，程序在执行时等待某个任务完成之后才能继续执行，通常是两个或者多个操作需要协同进行，且一个操作的完成依赖于另一个操作，比如购物，付款和发货是两个操作，必须要先付款才发货，不付款就没法发货
- **异步**：asyx，程序在执行时不需要等待某个任务完成，可以继续执行其他任务，就比如，购物我们买了一个商品，我们不用等到货后再去买别的，到货前我可以继续买，也可以继续做其他事情





## 2、多进程

### 1、多进程创建

​	创建进程需要用到multiprocessing模块

```python
# coding:UTF-8

import time


def nomu():
    for x in range(5):
        print(f"n1:{x}")
        time.sleep(1)


def nomu2():
    for x in range(5):
        print(f"n2:{x}")
        time.sleep(1)


if __name__ == '__main__':
    start = time.time()
    nomu()
    nomu2()
    end = time.time()
    print(rf'程序耗时{end - start}秒')

```

​	如上，不用多进程执行两个函数，此时执行完毕大概就是5+5秒

```python
# coding:UTF-8

import multiprocessing
import time,os


def nomu():
    for x in range(5):
        print(f"n1:{x},n2Fatherpid:{os.getppid()}")  # getppid可以获取父级的pid
        time.sleep(1)


def nomu2():
    for x in range(5):
        print(f"n2:{x},n2Fatherpid:{os.getppid()}")
        time.sleep(1)


if __name__ == '__main__':
    start = time.time()
    print(f'主进程ID:{os.getpid()}') # getpid是获取自身的pid
    
    p1 = multiprocessing.Process(target=nomu) # 创建进程对象，一个是target函数，一个是args，args接收元祖，比如args=('Hello',)
    p2 = multiprocessing.Process(target=nomu2)
    
    p1.start()  # 启动子进程
    p2.start()
    
    p1.join()  # 因为互不干扰，所以为了防止子进程未完毕，父进程挂掉，join阻塞让子进程执行完毕再去执行下面的父进程语句
    p2.join()
    end = time.time()
    print(rf'程序耗时{end - start}秒')

```

​	若我们改为了多进程代码，发现效率提高了，时间只消耗了一半，若进程对象特别多的时候，我们怎么写，要写一堆start和join吗？

```python
# coding:UTF-8

import multiprocessing
import time,os


def nomu():
    for x in range(5):
        print(f"n1:{x},n2Fatherpid:{os.getppid()}")
        time.sleep(1)


def nomu2():
    for x in range(5):
        print(f"n2:{x},n2Fatherpid:{os.getppid()}")
        time.sleep(1)


if __name__ == '__main__':
    start = time.time()
    print(f'主进程ID:{os.getpid()}')
    p1 = multiprocessing.Process(target=nomu)
    p2 = multiprocessing.Process(target=nomu2)

    for p in [p1,p2]:
        p.start()

    for p in [p1,p2]:
        p.join()
    end = time.time()
    print(rf'程序耗时{end - start}秒')

```

​	我们可以用到for循环



还有一种类创建的方式：

```python
# coding:UTF-8

from multiprocessing import Process
import time, os


class MyProcess(Process):
    def __init__(self, name):
        super().__init__()
        self.name = name

    def run(self):
        for x in range(5):
            print(f"多进程{self.name}开始工作,\
            自身pid:{os.getpid()}\
            父级pid:{os.getppid()}")
            time.sleep(1)


if __name__ == '__main__':
    start = time.time()
    print(f'主进程ID:{os.getpid()}')
    p1 = MyProcess('p1')
    p2 = MyProcess('p2')

    for p in [p1, p2]:
        p.start()

    for p in [p1, p2]:
        p.join()
    end = time.time()
    print(rf'程序耗时{end - start}秒')

```



​	多进程的缺陷：

- 通过进程模块执行的函数无法获取返回值，哪怕有Return
- 多个进程同时修改文件可能产生异常
- 进程数量多占用内存资源多



### 2、进程池

​	进程池是一种用于管理进程的工具，可以帮助我们在多核CPU上执行任务，提高程序执行效率

​	其实进程池就是一种资源池，维护着一个进程列表，任务来的时候，进程池从进程列表中选择一个进程，将任务分配给该进程执行，执行完毕后，将结果返回给进程池，进程池会将结果传递给等待结果的进程

​	所以进程池可以提高程序的执行效率，并且节省系统的资源（重复利用已经创建的进程，避免频繁创建和销毁），方便管理且方便扩展

```python
# coding:UTF-8

import multiprocessing,os,time

def myfun(name):
    print(name,os.getpid())
    time.sleep(1)

if __name__ == '__main__':
    pool = multiprocessing.Pool(5)  # 创建5个
    for i in range(15):
        pool.apply_async(myfun, args=(i,))  # 是异步的，也就是没有顺序的，不像同步顺序执行
    pool.close()
    pool.join()
```

​	观察如上部分，此时我们创建了一个5个的进程池，然后发布15个任务，我们发现每次执行5个，并且下一次执行的时候pid还是上次的，所以也就说明，虽然执行的任务不同了，但是还是使用的原来的资源，

​	以免主进程不等待结束了，子进程也就死了，就用到了join

​	虽然普通的创建进程无法返回值，但是进程池可以有

```python
# coding:UTF-8

import multiprocessing,os,time
def myfun(name):
    print(name,os.getpid())
    time.sleep(1)
    return os.getpid()

if __name__ == '__main__':
    pool = multiprocessing.Pool(5)  # 创建5个
    ret = []
    for i in range(15):
        result = pool.apply_async(myfun, args=(i,))  # 是异步的，也就是没有顺序的，不像同步顺序执行
        ret.append(result)
    pool.close()
    pool.join()
    for x in ret:
        print(x.get())
```

​	返回值通过get方法获取



### 3、进程锁

​	进程锁就是针对进程的锁，加了锁别人就没法再去操作了，解锁了别人就又能用了

​	就想上厕所，锁了门别人进不去，解开了别人才能用

```python
# coding:UTF-8

import multiprocessing,os,time
def myfun(name,lock):
    lock.acquire()  # 上锁
    print(name,os.getpid())
    time.sleep(1)
    lock.release()  # 解锁
    return os.getpid()

if __name__ == '__main__':
    manage = multiprocessing.Manager()
    lock = manage.Lock()  # 创建锁

    pool = multiprocessing.Pool(5)  # 创建5个
    ret = []
    for i in range(15):
        result = pool.apply_async(myfun, args=(i,lock))  # 是异步的，也就是没有顺序的，不像同步顺序执行
        ret.append(result)
    pool.close()
    pool.join()
    for x in ret:
        print(x.get())
```

​	此时我们就发现此时一个一个的执行，没法5个一起执行了，因为lock锁住了别人进不去了



### 4、进程通信

​	也就是两个进程之间的通信，进程的通信就像拿了一根管子，两人一人一头，互相输出

​	这里需要用到一个queue，队列，put放入参数，get提取参数

```python
# coding:UTF-8

import multiprocessing,sys


def send(q,message):
    if message == 'quit':
        sys.exit()
    q.put(message)


def recv(q):
    while True:
        message = q.get()
        print(message)
        if message == 'quit':
            break


if __name__ == '__main__':
    q = multiprocessing.Queue()

    p1 = multiprocessing.Process(target=send, args=(q,'hello'))
    p2 = multiprocessing.Process(target=recv, args=(q,))
    p1.start()
    p2.start()
    p1.join()
    p2.terminate()  # 进程里是死循环，无法等待其结束，只能强行终止:
```



## 3、多线程

​	线程比进程的资源消耗要低一些，常用threading模块

```python
# coding:UTF-8

import threading


class Mythread(threading.Thread):
    def __init__(self, name):
        super().__init__()
        self.name = name

    def run(self):
        print("Starting " + self.name)


if __name__ == '__main__':
    t1 = Mythread("Thread-1")
    t2 = Mythread("Thread-2")
    t1.start()
    t2.start()
    t1.join()
    t2.join()

```

​	和进程的操作大致相同，但是比进程要危险一些，因为线程共享进程资源，可能会造成错乱



### 1、线程池

​	线程池和进程池原理相同

```python
# coding:UTF-8

import threading, time
from concurrent.futures import ThreadPoolExecutor

def run(name):
    print(f"Running{name}")
    time.sleep(1)


if __name__ == '__main__':
    t = ThreadPoolExecutor(5)  # 创建5个
    for i in range(10):
        t.submit(run, (f'Thread-{i}',))

```

​	也可以加进程锁

```python
# coding:UTF-8

import threading, time
from concurrent.futures import ThreadPoolExecutor

def run(name):
    lock.acquire()
    print(f"Running{name}")
    time.sleep(1)
    lock.release()


if __name__ == '__main__':
    lock = threading.Lock()
    t = ThreadPoolExecutor(5)  # 创建5个
    for i in range(10):
        t.submit(run, (f'Thread-{i}',))

```

​	也可以获取返回值

```python
# coding:UTF-8

import threading, time
from concurrent.futures import ThreadPoolExecutor

def run(name):
    lock.acquire()
    print(f"Running{name}")
    time.sleep(1)
    lock.release()
    return name


if __name__ == '__main__':
    lock = threading.Lock()
    t = ThreadPoolExecutor(5)  # 创建5个
    lt = []
    for i in range(10):
        gg = t.submit(run, (f'Thread-{i}',))
        lt.append(gg)

    for x in lt:
        print(x.result())
```



### 2、加锁不加锁的区别

​	因为线程操作的是共享的资源，所以有时候会出错

```python
from threading import Thread
from time import sleep


class MyThread():

    def __init__(self):
        self.money = 1000

    def donation(self, money):
        new_money = self.money + money
        sleep(0.01)
        self.money = new_money

    @property
    def get_money(self):
        return self.money


class D_Thread(Thread):
    def __init__(self, myTh, money):
        super().__init__()
        self.MTh = myTh
        self.money = money

    def run(self):
        self.MTh.donation(self.money)


if __name__ == '__main__':
    my = MyThread()
    thread = []
    for _ in range(50):
        t = D_Thread(my, 100)
        thread.append(t)
        t.start()

    for t in thread:
        t.join()

    print(f'捐赠完毕，账户余额为{my.get_money}')
```

​	看这段代码，50个人给一个人捐赠，一个人100，那应该是5000+1000=6000，但是执行完代码不超2000元

​	这就是一个资源被多个线程竞争，成为了临界资源，如果不加保护会产生不准确的数据

```python
from threading import Thread,Lock
from time import sleep


class MyThread():

    def __init__(self):
        self.money = 1000

    def donation(self, money):
        Lock1.acquire() # 有锁才能执行
        new_money = self.money + money
        sleep(0.01)
        self.money = new_money
        Lock1.release() # 释放锁

    @property
    def get_money(self):
        return self.money


class D_Thread(Thread):
    def __init__(self, myTh, money):
        super().__init__()
        self.MTh = myTh
        self.money = money

    def run(self):
        self.MTh.donation(self.money)


if __name__ == '__main__':
    my = MyThread()
    thread = []
    Lock1 = Lock()
    for _ in range(50):
        t = D_Thread(my, 100)
        thread.append(t)
        t.start()

    for t in thread:
        t.join()

    print(f'捐赠完毕，账户余额为{my.get_money}')
```

​	首先通过Lock创建了一把锁，到acquire，锁就被线程拿走了，其他的就会阻塞，一直到release释放了锁，才会继续执行



## 4、全局锁

​	Python有一个GIL全局锁，造成了只能在单一的cpu工作，无法实现真正的多线程





## 5、异步

​	多进程和多线程都是在一个进程中创建多个进程或者多个线程

​	**异步**：asyx，程序在执行时不需要等待某个任务完成，可以继续执行其他任务，就比如，购物我们买了一个商品，我们不用等到货后再去买别的，到货前我可以继续买，也可以继续做其他事情

```python
# coding:UTF-8

import time,random

def a():
    for i in range(10):
        print(i,"a")
        time.sleep(random.randint(1,2))
    return 'a function'

def b():
    for i in range(10):
        print(i,"b")
        time.sleep(random.randint(1,2))
    return 'b function'

if __name__ == '__main__':
    a(),b()
```

​	先看没有异步，自上向下顺序执行

```python
# coding:UTF-8

import time, random, asyncio


async def a():
    for i in range(10):
        print(i, "a")
        await asyncio.sleep(random.randint(1, 2))
    return 'a function'


async def b():
    for i in range(10):
        print(i, "b")
        await asyncio.sleep(random.randint(1, 2))
    return 'b function'


async def main():
    await asyncio.gather(a(), b())


if __name__ == '__main__':
    start = time.time()
    asyncio.run(main())
    end = time.time() - start
    print('\n%f seconds' % end)

```

​	再来看下异步代码。发现就是交替执行了

- async：声明一个函数为异步函数
- await：执行异步
- asyncio.gather：将异步函数批量执行
- asyncio.run：执行主异步函数
- asyncio.sleep：暂停等待，time的是cpu级别的，会干扰异步
